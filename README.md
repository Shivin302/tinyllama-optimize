# tinyllama-optimization
Optimize inference for TinyLlama
